---
title: "Trainer"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Packages

```{r}
pacman::p_load(tidyverse, purrr, furrr, keras, xgboost, h2o, deeplyr, mlgraph)
devtools::document()
#devtools::load_all()
options(scipen = 999)
# devtools::install()
```




# CV Test Data

```{r}
N <- 1000
df <- tibble(
  split = sample(1:3, size = N, prob = c(.8, .1, .1), replace = T),
  split_cv = sample(1:5, size = N, prob = rep(.2, 5), replace = T),
  x1 = rnorm(N),
  x2 = rnorm(N),
  z = 2*x1 + 3*x2 + rnorm(N),
  y = ifelse(z > mean(z), 1, 0), #2*x1 + 2*x2 + rnorm(1000)
  y_multi0 = case_when(z > (mean(z)+.2*sd(z)) ~ 0, z < (mean(z)-.2*sd(z)) ~ 2, T ~ 1),
  y_multi1 = y_multi0 + 1
) %>%
  glimpse

df %>%
  count(split_cv, y)
```


# Binary

```{r}
sp_binary <- split_sample(x = df[,c("x1", "x2")], id = df$split, y = df$y, meta = df)
sp_binary_cv <- split_sample(x = df[,c("x1", "x2")], id = df$split_cv, y = df$y, meta = df)
```



# GA

```{r}
devtools::document()

hyper_xgboost <- list(
  eta = p_double(.1, .9),
  max_depth = p_integer(3L, 30L),
  subsample = p_double(.3, 1),
  lambda =  p_double(0, 1),
  alpha =  p_double(0, 1)
)
# static <- list()

my_xgboost <- function(params, data, path){
  
  f <- fit_cv(params, data, task = "binary", backend = "xgboost", path = path)
  
  mlgraph::eval_classifier(f$preds, target, pred, prob, path = path)
  
  return(f$metrics)
  #return(-m$perform$rmse)
}

ga1 <- genetic$new("ga_multi_xgboost")

ga1$set(
  process = my_xgboost,
  hypers = hyper_xgboost, 
  params = list(), 
  data = sp_binary_cv, 
  metric = "cv_accuracy",
  minimize = F
)

ga1$compute(
  popSize = 10, 
  maxiter = 3, # main run argument 
  run = 3
)
```






```{r}
plot(ga1$model)
```



```{r}

```

